{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name : Mahesh Jagtap  Reg No 24MCS1017                                          \n",
        "Part - B : Implement the MLP by using any dataset of your choice. Choose the data specific to any domain."
      ],
      "metadata": {
        "id": "Phc0vLxI8uaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **1.Objective:**\n",
        "\n",
        "The objective of this project is to predict the presence or absence of heart disease based on patient attributes using a Multi-Layer Perceptron (MLP). The MLP model will be implemented, fine-tuned with different parameters, and evaluated to determine the most efficient configuration. The goal is to experiment with various settings like the number of hidden layers, the number of neurons in each layer, optimizers, and epochs."
      ],
      "metadata": {
        "id": "mapoRQPR81n3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Data Set Description :**\n",
        "\n",
        "The \"Heart Disease UCI\" dataset contains 303 records, with 14 attributes. The target variable is binary, representing whether a patient has heart disease (1) or not (0). The attributes in the dataset are:\n",
        "\n",
        "Age: Age of the patient (numeric).\n",
        "\n",
        "Sex: Gender of the patient (1 = male, 0 = female).\n",
        "\n",
        "Chest Pain Type: Type of chest pain (values range from 1 to 4).\n",
        "\n",
        "Resting Blood Pressure: Blood pressure in mm Hg (numeric).\n",
        "\n",
        "Serum Cholesterol: Serum cholesterol in mg/dl (numeric).\n",
        "\n",
        "Fasting Blood Sugar: Blood sugar level (1 = greater than 120 mg/dl, 0 = less than or equal to 120 mg/dl).\n",
        "\n",
        "Resting Electrocardiographic Results: Electrocardiographic results (values range from 0 to 2).\n",
        "\n",
        "Maximum Heart Rate Achieved: Maximum heart rate achieved during exercise (numeric).\n",
        "\n",
        "Exercise Induced Angina: Whether exercise induced angina (1 = yes, 0 = no).\n",
        "\n",
        "Oldpeak: ST depression induced by exercise relative to rest (numeric).\n",
        "Slope of Peak Exercise ST Segment: Slope of the peak exercise ST segment (values range from 1 to 3).\n",
        "\n",
        "Number of Major Vessels Colored by Fluoroscopy: Number of vessels colored by fluoroscopy (values range from 0 to 3).\n",
        "\n",
        "Thalassemia: Thalassemia (values 3 = normal, 6 = fixed defect, 7 = reversable defect).\n",
        "\n",
        "Presence of Heart Disease: Target variable (1 = heart disease present, 0 = no heart disease)."
      ],
      "metadata": {
        "id": "W0we-rbZ9c5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Experiments**\n",
        "\n",
        "Step 1: Baseline Model Implementation\n"
      ],
      "metadata": {
        "id": "nEM6U8b3-NuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "file_path = 'heart_disease.csv'  # Ensure the file is in the current working directory\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Dataset Preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display the structure of the dataset\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQv0X7KfFqWD",
        "outputId": "31dd34c4-0088-4127-d2d3-e97c6b4df995"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
            "0   69    1   0       160   234    1        2      131      0      0.1      1   \n",
            "1   69    0   0       140   239    0        0      151      0      1.8      0   \n",
            "2   66    0   0       150   226    0        0      114      0      2.6      2   \n",
            "3   65    1   0       138   282    1        2      174      0      1.4      1   \n",
            "4   64    1   0       110   211    0        2      144      1      1.8      1   \n",
            "\n",
            "   ca  thal  condition  \n",
            "0   1     0          0  \n",
            "1   2     0          0  \n",
            "2   0     0          0  \n",
            "3   1     0          1  \n",
            "4   0     0          0  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 297 entries, 0 to 296\n",
            "Data columns (total 14 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   age        297 non-null    int64  \n",
            " 1   sex        297 non-null    int64  \n",
            " 2   cp         297 non-null    int64  \n",
            " 3   trestbps   297 non-null    int64  \n",
            " 4   chol       297 non-null    int64  \n",
            " 5   fbs        297 non-null    int64  \n",
            " 6   restecg    297 non-null    int64  \n",
            " 7   thalach    297 non-null    int64  \n",
            " 8   exang      297 non-null    int64  \n",
            " 9   oldpeak    297 non-null    float64\n",
            " 10  slope      297 non-null    int64  \n",
            " 11  ca         297 non-null    int64  \n",
            " 12  thal       297 non-null    int64  \n",
            " 13  condition  297 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 32.6 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df.drop(columns=[\"condition\"])\n",
        "y = df[\"condition\"]\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "46ODVjadG0FE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Build a baseline model\n",
        "def build_baseline_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=X_train.shape[1], activation='relu'))  # One hidden layer with 12 neurons\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train the baseline model\n",
        "baseline_model = build_baseline_model()\n",
        "baseline_history = baseline_model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Evaluate the baseline model\n",
        "loss, accuracy = baseline_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Baseline Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsR8Utj0HpkJ",
        "outputId": "b28d2713-9ee5-40a5-9858-c759298e86ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5172 - loss: 0.8780 - val_accuracy: 0.5833 - val_loss: 0.7323\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5461 - loss: 0.8016 - val_accuracy: 0.6000 - val_loss: 0.6848\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5786 - loss: 0.7230 - val_accuracy: 0.6167 - val_loss: 0.6503\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6384 - loss: 0.6534 - val_accuracy: 0.6333 - val_loss: 0.6222\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6600 - loss: 0.5983 - val_accuracy: 0.6500 - val_loss: 0.5965\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6858 - loss: 0.5917 - val_accuracy: 0.6500 - val_loss: 0.5741\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.5634 - val_accuracy: 0.6667 - val_loss: 0.5537\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7665 - loss: 0.5166 - val_accuracy: 0.6667 - val_loss: 0.5368\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.4827 - val_accuracy: 0.6667 - val_loss: 0.5227\n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.4598 - val_accuracy: 0.7333 - val_loss: 0.5115\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8482 - loss: 0.4097 - val_accuracy: 0.7333 - val_loss: 0.5030\n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.4271 - val_accuracy: 0.7500 - val_loss: 0.4969\n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8242 - loss: 0.4091 - val_accuracy: 0.7667 - val_loss: 0.4939\n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.3743 - val_accuracy: 0.7500 - val_loss: 0.4909\n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8449 - loss: 0.3965 - val_accuracy: 0.7333 - val_loss: 0.4883\n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.4026 - val_accuracy: 0.7333 - val_loss: 0.4886\n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.3518 - val_accuracy: 0.7500 - val_loss: 0.4896\n",
            "Epoch 18/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.3293 - val_accuracy: 0.7500 - val_loss: 0.4917\n",
            "Epoch 19/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8708 - loss: 0.3383 - val_accuracy: 0.7500 - val_loss: 0.4926\n",
            "Epoch 20/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9008 - loss: 0.3016 - val_accuracy: 0.7667 - val_loss: 0.4954\n",
            "Epoch 21/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.3366 - val_accuracy: 0.7667 - val_loss: 0.4978\n",
            "Epoch 22/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8698 - loss: 0.3289 - val_accuracy: 0.7667 - val_loss: 0.4996\n",
            "Epoch 23/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8551 - loss: 0.3347 - val_accuracy: 0.7667 - val_loss: 0.5022\n",
            "Epoch 24/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 0.3349 - val_accuracy: 0.7667 - val_loss: 0.5040\n",
            "Epoch 25/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.3235 - val_accuracy: 0.7667 - val_loss: 0.5068\n",
            "Epoch 26/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8715 - loss: 0.3047 - val_accuracy: 0.7667 - val_loss: 0.5087\n",
            "Epoch 27/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8595 - loss: 0.3100 - val_accuracy: 0.7667 - val_loss: 0.5114\n",
            "Epoch 28/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9008 - loss: 0.2712 - val_accuracy: 0.7667 - val_loss: 0.5134\n",
            "Epoch 29/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8864 - loss: 0.3013 - val_accuracy: 0.7667 - val_loss: 0.5166\n",
            "Epoch 30/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8646 - loss: 0.3166 - val_accuracy: 0.7667 - val_loss: 0.5196\n",
            "Epoch 31/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.2689 - val_accuracy: 0.7667 - val_loss: 0.5249\n",
            "Epoch 32/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8742 - loss: 0.3202 - val_accuracy: 0.7667 - val_loss: 0.5262\n",
            "Epoch 33/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8909 - loss: 0.3098 - val_accuracy: 0.7667 - val_loss: 0.5292\n",
            "Epoch 34/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8730 - loss: 0.2803 - val_accuracy: 0.7667 - val_loss: 0.5328\n",
            "Epoch 35/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8563 - loss: 0.3324 - val_accuracy: 0.7667 - val_loss: 0.5343\n",
            "Epoch 36/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.2538 - val_accuracy: 0.7667 - val_loss: 0.5379\n",
            "Epoch 37/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2436 - val_accuracy: 0.7667 - val_loss: 0.5428\n",
            "Epoch 38/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.2972 - val_accuracy: 0.7667 - val_loss: 0.5458\n",
            "Epoch 39/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.2971 - val_accuracy: 0.7500 - val_loss: 0.5511\n",
            "Epoch 40/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.2693 - val_accuracy: 0.7667 - val_loss: 0.5516\n",
            "Epoch 41/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.2663 - val_accuracy: 0.7667 - val_loss: 0.5528\n",
            "Epoch 42/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.2873 - val_accuracy: 0.7667 - val_loss: 0.5560\n",
            "Epoch 43/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.2538 - val_accuracy: 0.7667 - val_loss: 0.5580\n",
            "Epoch 44/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.2374 - val_accuracy: 0.7667 - val_loss: 0.5610\n",
            "Epoch 45/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.2917 - val_accuracy: 0.7667 - val_loss: 0.5636\n",
            "Epoch 46/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8738 - loss: 0.2662 - val_accuracy: 0.7667 - val_loss: 0.5658\n",
            "Epoch 47/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9005 - loss: 0.2404 - val_accuracy: 0.7667 - val_loss: 0.5703\n",
            "Epoch 48/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9082 - loss: 0.2488 - val_accuracy: 0.7667 - val_loss: 0.5696\n",
            "Epoch 49/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.2347 - val_accuracy: 0.7667 - val_loss: 0.5722\n",
            "Epoch 50/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8988 - loss: 0.2650 - val_accuracy: 0.7667 - val_loss: 0.5767\n",
            "Baseline Model Accuracy: 76.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = (baseline_model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Print a sample of predictions and actual values\n",
        "print(\"\\nPredictions vs Actual Values:\")\n",
        "comparison = pd.DataFrame({\"Predicted\": predictions.flatten(), \"Actual\": y_test.reset_index(drop=True)})\n",
        "print(comparison.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNaOxmzsHx1P",
        "outputId": "6040cb15-bfe6-4e4b-edee-8fb40d46a0c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\n",
            "Predictions vs Actual Values:\n",
            "   Predicted  Actual\n",
            "0          1       1\n",
            "1          1       1\n",
            "2          0       0\n",
            "3          0       0\n",
            "4          1       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-Tuned Model 1: Increase Hidden Layers**\n",
        "\n"
      ],
      "metadata": {
        "id": "Jz8n9NVNapJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a fine-tuned model with increased hidden layers\n",
        "def build_model_more_layers():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))  # First hidden layer\n",
        "    model.add(Dense(8, activation='relu'))  # Second hidden layer\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Training the fine-tuned model\n",
        "model_more_layers = build_model_more_layers()\n",
        "history_more_layers = model_more_layers.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Evaluating the fine-tuned model\n",
        "loss, accuracy = model_more_layers.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Fine-Tuned Model 1 (More Layers) Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRASBGV9Sw3x",
        "outputId": "b4757c07-e73c-4b01-95f9-f57720564624"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5638 - loss: 0.7174 - val_accuracy: 0.4833 - val_loss: 0.6946\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 0.6388 - val_accuracy: 0.6167 - val_loss: 0.6531\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6704 - loss: 0.6043 - val_accuracy: 0.6667 - val_loss: 0.6204\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7789 - loss: 0.5463 - val_accuracy: 0.7167 - val_loss: 0.5945\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.5027 - val_accuracy: 0.6667 - val_loss: 0.5742\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7778 - loss: 0.4920 - val_accuracy: 0.6833 - val_loss: 0.5629\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 0.3942 - val_accuracy: 0.7167 - val_loss: 0.5568\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3875 - val_accuracy: 0.7000 - val_loss: 0.5550\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8752 - loss: 0.3295 - val_accuracy: 0.7000 - val_loss: 0.5562\n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.4052 - val_accuracy: 0.7167 - val_loss: 0.5570\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8652 - loss: 0.3622 - val_accuracy: 0.7167 - val_loss: 0.5609\n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.3322 - val_accuracy: 0.7167 - val_loss: 0.5618\n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2832 - val_accuracy: 0.7167 - val_loss: 0.5682\n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8782 - loss: 0.3001 - val_accuracy: 0.7167 - val_loss: 0.5688\n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8455 - loss: 0.3373 - val_accuracy: 0.6833 - val_loss: 0.5742\n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8806 - loss: 0.3194 - val_accuracy: 0.7000 - val_loss: 0.5738\n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8337 - loss: 0.3337 - val_accuracy: 0.7000 - val_loss: 0.5781\n",
            "Epoch 18/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8843 - loss: 0.2792 - val_accuracy: 0.7000 - val_loss: 0.5841\n",
            "Epoch 19/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.2896 - val_accuracy: 0.6833 - val_loss: 0.5890\n",
            "Epoch 20/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.2555 - val_accuracy: 0.6833 - val_loss: 0.5947\n",
            "Epoch 21/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.2833 - val_accuracy: 0.6833 - val_loss: 0.6007\n",
            "Epoch 22/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.2515 - val_accuracy: 0.6833 - val_loss: 0.6027\n",
            "Epoch 23/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2460 - val_accuracy: 0.7000 - val_loss: 0.6044\n",
            "Epoch 24/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2120 - val_accuracy: 0.6833 - val_loss: 0.6124\n",
            "Epoch 25/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.2336 - val_accuracy: 0.7000 - val_loss: 0.6178\n",
            "Epoch 26/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.2223 - val_accuracy: 0.7000 - val_loss: 0.6228\n",
            "Epoch 27/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2323 - val_accuracy: 0.7000 - val_loss: 0.6278\n",
            "Epoch 28/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.2201 - val_accuracy: 0.6833 - val_loss: 0.6312\n",
            "Epoch 29/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9297 - loss: 0.2307 - val_accuracy: 0.6833 - val_loss: 0.6395\n",
            "Epoch 30/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2609 - val_accuracy: 0.6833 - val_loss: 0.6424\n",
            "Epoch 31/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.2426 - val_accuracy: 0.6833 - val_loss: 0.6478\n",
            "Epoch 32/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8680 - loss: 0.3093 - val_accuracy: 0.7000 - val_loss: 0.6514\n",
            "Epoch 33/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9028 - loss: 0.2488 - val_accuracy: 0.6833 - val_loss: 0.6607\n",
            "Epoch 34/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9295 - loss: 0.1970 - val_accuracy: 0.7000 - val_loss: 0.6680\n",
            "Epoch 35/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9139 - loss: 0.2264 - val_accuracy: 0.7000 - val_loss: 0.6703\n",
            "Epoch 36/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.2125 - val_accuracy: 0.7000 - val_loss: 0.6767\n",
            "Epoch 37/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.2447 - val_accuracy: 0.7000 - val_loss: 0.6835\n",
            "Epoch 38/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1731 - val_accuracy: 0.7000 - val_loss: 0.6878\n",
            "Epoch 39/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.2104 - val_accuracy: 0.7000 - val_loss: 0.6929\n",
            "Epoch 40/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.1886 - val_accuracy: 0.7000 - val_loss: 0.7000\n",
            "Epoch 41/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.2142 - val_accuracy: 0.7000 - val_loss: 0.7081\n",
            "Epoch 42/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2311 - val_accuracy: 0.7000 - val_loss: 0.7126\n",
            "Epoch 43/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9288 - loss: 0.1988 - val_accuracy: 0.7000 - val_loss: 0.7169\n",
            "Epoch 44/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.1953 - val_accuracy: 0.7000 - val_loss: 0.7242\n",
            "Epoch 45/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9484 - loss: 0.1750 - val_accuracy: 0.7000 - val_loss: 0.7328\n",
            "Epoch 46/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.1975 - val_accuracy: 0.7000 - val_loss: 0.7355\n",
            "Epoch 47/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.2156 - val_accuracy: 0.7000 - val_loss: 0.7413\n",
            "Epoch 48/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9296 - loss: 0.1766 - val_accuracy: 0.7000 - val_loss: 0.7519\n",
            "Epoch 49/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.1924 - val_accuracy: 0.7000 - val_loss: 0.7560\n",
            "Epoch 50/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 0.1843 - val_accuracy: 0.7000 - val_loss: 0.7628\n",
            "Fine-Tuned Model 1 (More Layers) Accuracy: 70.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-Tuned Model 2: Change Number of Neurons in Hidden Layers**\n",
        "\n"
      ],
      "metadata": {
        "id": "EiMZreX0azON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a fine-tuned model with more neurons\n",
        "def build_model_more_neurons():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))  # Larger hidden layer\n",
        "    model.add(Dense(16, activation='relu'))  # Second hidden layer\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Training the fine-tuned model\n",
        "model_more_neurons = build_model_more_neurons()\n",
        "history_more_neurons = model_more_neurons.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Evaluating the fine-tuned model\n",
        "loss, accuracy = model_more_neurons.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Fine-Tuned Model 2 (More Neurons) Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwf-XzKBS6vn",
        "outputId": "4fd3ed6f-97d1-447b-ce91-0e94b1daf35e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4878 - loss: 0.7015 - val_accuracy: 0.6000 - val_loss: 0.6630\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7802 - loss: 0.6234 - val_accuracy: 0.6500 - val_loss: 0.6211\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.5619 - val_accuracy: 0.7000 - val_loss: 0.5815\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8519 - loss: 0.4890 - val_accuracy: 0.7000 - val_loss: 0.5522\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.4251 - val_accuracy: 0.6833 - val_loss: 0.5379\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.4280 - val_accuracy: 0.6833 - val_loss: 0.5366\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9025 - loss: 0.3306 - val_accuracy: 0.7000 - val_loss: 0.5440\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9024 - loss: 0.3027 - val_accuracy: 0.7167 - val_loss: 0.5521\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8649 - loss: 0.3479 - val_accuracy: 0.7000 - val_loss: 0.5624\n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8999 - loss: 0.2909 - val_accuracy: 0.7000 - val_loss: 0.5710\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2476 - val_accuracy: 0.7333 - val_loss: 0.5894\n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.3113 - val_accuracy: 0.7333 - val_loss: 0.6008\n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2497 - val_accuracy: 0.7333 - val_loss: 0.6015\n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2289 - val_accuracy: 0.7333 - val_loss: 0.6188\n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.2814 - val_accuracy: 0.7500 - val_loss: 0.6237\n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9104 - loss: 0.2286 - val_accuracy: 0.7500 - val_loss: 0.6338\n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9321 - loss: 0.1967 - val_accuracy: 0.7500 - val_loss: 0.6484\n",
            "Epoch 18/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.2427 - val_accuracy: 0.7500 - val_loss: 0.6504\n",
            "Epoch 19/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.1979 - val_accuracy: 0.7500 - val_loss: 0.6581\n",
            "Epoch 20/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.2339 - val_accuracy: 0.7667 - val_loss: 0.6664\n",
            "Epoch 21/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9326 - loss: 0.1843 - val_accuracy: 0.7500 - val_loss: 0.6731\n",
            "Epoch 22/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9173 - loss: 0.2152 - val_accuracy: 0.7500 - val_loss: 0.6785\n",
            "Epoch 23/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.2036 - val_accuracy: 0.7333 - val_loss: 0.6835\n",
            "Epoch 24/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.2252 - val_accuracy: 0.7667 - val_loss: 0.6899\n",
            "Epoch 25/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9369 - loss: 0.1883 - val_accuracy: 0.7333 - val_loss: 0.6960\n",
            "Epoch 26/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8763 - loss: 0.2643 - val_accuracy: 0.7500 - val_loss: 0.7027\n",
            "Epoch 27/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1477 - val_accuracy: 0.7500 - val_loss: 0.7095\n",
            "Epoch 28/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9478 - loss: 0.1464 - val_accuracy: 0.7333 - val_loss: 0.7124\n",
            "Epoch 29/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2009 - val_accuracy: 0.7500 - val_loss: 0.7223\n",
            "Epoch 30/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9323 - loss: 0.1834 - val_accuracy: 0.7500 - val_loss: 0.7288\n",
            "Epoch 31/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9546 - loss: 0.1344 - val_accuracy: 0.7333 - val_loss: 0.7401\n",
            "Epoch 32/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9277 - loss: 0.1800 - val_accuracy: 0.7333 - val_loss: 0.7445\n",
            "Epoch 33/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.1770 - val_accuracy: 0.7167 - val_loss: 0.7489\n",
            "Epoch 34/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.1471 - val_accuracy: 0.7167 - val_loss: 0.7666\n",
            "Epoch 35/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9537 - loss: 0.1399 - val_accuracy: 0.7167 - val_loss: 0.7684\n",
            "Epoch 36/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.1252 - val_accuracy: 0.7000 - val_loss: 0.7804\n",
            "Epoch 37/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9570 - loss: 0.1308 - val_accuracy: 0.7000 - val_loss: 0.7856\n",
            "Epoch 38/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9568 - loss: 0.1379 - val_accuracy: 0.7000 - val_loss: 0.7980\n",
            "Epoch 39/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9504 - loss: 0.1220 - val_accuracy: 0.7000 - val_loss: 0.8014\n",
            "Epoch 40/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.1151 - val_accuracy: 0.7000 - val_loss: 0.8057\n",
            "Epoch 41/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1290 - val_accuracy: 0.7000 - val_loss: 0.8209\n",
            "Epoch 42/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1257 - val_accuracy: 0.7000 - val_loss: 0.8237\n",
            "Epoch 43/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1243 - val_accuracy: 0.7000 - val_loss: 0.8299\n",
            "Epoch 44/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.1031 - val_accuracy: 0.7000 - val_loss: 0.8444\n",
            "Epoch 45/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1177 - val_accuracy: 0.7000 - val_loss: 0.8509\n",
            "Epoch 46/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9756 - loss: 0.1140 - val_accuracy: 0.7000 - val_loss: 0.8548\n",
            "Epoch 47/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0885 - val_accuracy: 0.7000 - val_loss: 0.8705\n",
            "Epoch 48/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0955 - val_accuracy: 0.7000 - val_loss: 0.8683\n",
            "Epoch 49/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9735 - loss: 0.1061 - val_accuracy: 0.7000 - val_loss: 0.8765\n",
            "Epoch 50/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9470 - loss: 0.1335 - val_accuracy: 0.7000 - val_loss: 0.8919\n",
            "Fine-Tuned Model 2 (More Neurons) Accuracy: 70.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-Tuned Model 3: Change Optimizer**"
      ],
      "metadata": {
        "id": "0YUfaEMsa2rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a fine-tuned model with a different optimizer (SGD)\n",
        "def build_model_different_optimizer():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Training the fine-tuned model\n",
        "model_different_optimizer = build_model_different_optimizer()\n",
        "history_different_optimizer = model_different_optimizer.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Evaluating the fine-tuned model\n",
        "loss, accuracy = model_different_optimizer.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Fine-Tuned Model 3 (Different Optimizer) Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eumoSjihTDLS",
        "outputId": "f3fbff32-9c10-481e-d1fd-a54a5d333454"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5706 - loss: 0.6766 - val_accuracy: 0.6000 - val_loss: 0.7164\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6052 - loss: 0.6372 - val_accuracy: 0.6000 - val_loss: 0.6937\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6334 - loss: 0.6254 - val_accuracy: 0.6000 - val_loss: 0.6753\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6660 - loss: 0.6049 - val_accuracy: 0.6333 - val_loss: 0.6594\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.5402 - val_accuracy: 0.6667 - val_loss: 0.6456\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.5420 - val_accuracy: 0.6667 - val_loss: 0.6328\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7545 - loss: 0.5010 - val_accuracy: 0.6333 - val_loss: 0.6213\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.4831 - val_accuracy: 0.6333 - val_loss: 0.6106\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.4588 - val_accuracy: 0.6500 - val_loss: 0.6008\n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8045 - loss: 0.4539 - val_accuracy: 0.6500 - val_loss: 0.5928\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7592 - loss: 0.4768 - val_accuracy: 0.6500 - val_loss: 0.5864\n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7715 - loss: 0.4608 - val_accuracy: 0.6500 - val_loss: 0.5821\n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.4289 - val_accuracy: 0.6667 - val_loss: 0.5787\n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.4374 - val_accuracy: 0.7000 - val_loss: 0.5762\n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.3943 - val_accuracy: 0.7000 - val_loss: 0.5744\n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8187 - loss: 0.4079 - val_accuracy: 0.7000 - val_loss: 0.5729\n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.3995 - val_accuracy: 0.7000 - val_loss: 0.5720\n",
            "Epoch 18/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3773 - val_accuracy: 0.6833 - val_loss: 0.5710\n",
            "Epoch 19/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.3763 - val_accuracy: 0.6833 - val_loss: 0.5704\n",
            "Epoch 20/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8526 - loss: 0.3530 - val_accuracy: 0.6833 - val_loss: 0.5700\n",
            "Epoch 21/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.3301 - val_accuracy: 0.6833 - val_loss: 0.5700\n",
            "Epoch 22/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.3441 - val_accuracy: 0.6833 - val_loss: 0.5701\n",
            "Epoch 23/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 0.3436 - val_accuracy: 0.6833 - val_loss: 0.5700\n",
            "Epoch 24/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8708 - loss: 0.3236 - val_accuracy: 0.6833 - val_loss: 0.5699\n",
            "Epoch 25/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8688 - loss: 0.3477 - val_accuracy: 0.6833 - val_loss: 0.5700\n",
            "Epoch 26/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8364 - loss: 0.3809 - val_accuracy: 0.6833 - val_loss: 0.5702\n",
            "Epoch 27/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.3550 - val_accuracy: 0.6833 - val_loss: 0.5707\n",
            "Epoch 28/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8689 - loss: 0.3342 - val_accuracy: 0.7000 - val_loss: 0.5715\n",
            "Epoch 29/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.3336 - val_accuracy: 0.7000 - val_loss: 0.5717\n",
            "Epoch 30/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.3531 - val_accuracy: 0.7000 - val_loss: 0.5720\n",
            "Epoch 31/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8575 - loss: 0.3448 - val_accuracy: 0.7000 - val_loss: 0.5732\n",
            "Epoch 32/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8481 - loss: 0.3587 - val_accuracy: 0.7000 - val_loss: 0.5741\n",
            "Epoch 33/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8676 - loss: 0.2967 - val_accuracy: 0.7000 - val_loss: 0.5753\n",
            "Epoch 34/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8149 - loss: 0.3875 - val_accuracy: 0.7000 - val_loss: 0.5766\n",
            "Epoch 35/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3452 - val_accuracy: 0.7000 - val_loss: 0.5781\n",
            "Epoch 36/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8544 - loss: 0.3210 - val_accuracy: 0.7000 - val_loss: 0.5784\n",
            "Epoch 37/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8805 - loss: 0.2909 - val_accuracy: 0.7000 - val_loss: 0.5790\n",
            "Epoch 38/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8619 - loss: 0.3521 - val_accuracy: 0.7000 - val_loss: 0.5798\n",
            "Epoch 39/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.2949 - val_accuracy: 0.7000 - val_loss: 0.5803\n",
            "Epoch 40/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.3009 - val_accuracy: 0.7000 - val_loss: 0.5809\n",
            "Epoch 41/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2787 - val_accuracy: 0.7000 - val_loss: 0.5814\n",
            "Epoch 42/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8568 - loss: 0.3097 - val_accuracy: 0.7000 - val_loss: 0.5819\n",
            "Epoch 43/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.2810 - val_accuracy: 0.7000 - val_loss: 0.5827\n",
            "Epoch 44/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.3180 - val_accuracy: 0.7167 - val_loss: 0.5837\n",
            "Epoch 45/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.3673 - val_accuracy: 0.7167 - val_loss: 0.5847\n",
            "Epoch 46/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.3039 - val_accuracy: 0.7167 - val_loss: 0.5853\n",
            "Epoch 47/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.2356 - val_accuracy: 0.7167 - val_loss: 0.5853\n",
            "Epoch 48/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8696 - loss: 0.2871 - val_accuracy: 0.7167 - val_loss: 0.5865\n",
            "Epoch 49/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3186 - val_accuracy: 0.7167 - val_loss: 0.5879\n",
            "Epoch 50/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.2726 - val_accuracy: 0.7167 - val_loss: 0.5884\n",
            "Fine-Tuned Model 3 (Different Optimizer) Accuracy: 71.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-Tuned Model 4: Increase Epochs**\n",
        "\n"
      ],
      "metadata": {
        "id": "6fyO0ddobBdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a model with increased epochs for training\n",
        "model_more_epochs = build_baseline_model()  # Use baseline architecture\n",
        "\n",
        "# Training the model with more epochs\n",
        "history_more_epochs = model_more_epochs.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "loss, accuracy = model_more_epochs.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Fine-Tuned Model 4 (More Epochs) Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVvGOh9WTKj3",
        "outputId": "bd27712d-44dc-4f41-bff9-f4fcd696e79e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4656 - loss: 0.7635 - val_accuracy: 0.5500 - val_loss: 0.7029\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4897 - loss: 0.7270 - val_accuracy: 0.6333 - val_loss: 0.6485\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6696 - loss: 0.6285 - val_accuracy: 0.6833 - val_loss: 0.6067\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7122 - loss: 0.5726 - val_accuracy: 0.7000 - val_loss: 0.5755\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7626 - loss: 0.5367 - val_accuracy: 0.7167 - val_loss: 0.5509\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7579 - loss: 0.5178 - val_accuracy: 0.7333 - val_loss: 0.5343\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8095 - loss: 0.4589 - val_accuracy: 0.7500 - val_loss: 0.5209\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8194 - loss: 0.4374 - val_accuracy: 0.7500 - val_loss: 0.5112\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4385 - val_accuracy: 0.7500 - val_loss: 0.5046\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8491 - loss: 0.3940 - val_accuracy: 0.7667 - val_loss: 0.4983\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8004 - loss: 0.4436 - val_accuracy: 0.7667 - val_loss: 0.4939\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4091 - val_accuracy: 0.7667 - val_loss: 0.4909\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7986 - loss: 0.4063 - val_accuracy: 0.7667 - val_loss: 0.4891\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.3856 - val_accuracy: 0.7667 - val_loss: 0.4875\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8688 - loss: 0.3209 - val_accuracy: 0.7667 - val_loss: 0.4880\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8632 - loss: 0.3420 - val_accuracy: 0.7667 - val_loss: 0.4879\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8388 - loss: 0.3435 - val_accuracy: 0.7667 - val_loss: 0.4885\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8538 - loss: 0.3162 - val_accuracy: 0.7667 - val_loss: 0.4885\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8273 - loss: 0.3490 - val_accuracy: 0.7667 - val_loss: 0.4905\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8702 - loss: 0.3213 - val_accuracy: 0.7667 - val_loss: 0.4917\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.3204 - val_accuracy: 0.7667 - val_loss: 0.4935\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8587 - loss: 0.3258 - val_accuracy: 0.7667 - val_loss: 0.4954\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8461 - loss: 0.3457 - val_accuracy: 0.7667 - val_loss: 0.4979\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.2778 - val_accuracy: 0.7667 - val_loss: 0.4997\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8740 - loss: 0.2910 - val_accuracy: 0.7667 - val_loss: 0.5013\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8458 - loss: 0.2942 - val_accuracy: 0.7667 - val_loss: 0.5037\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8569 - loss: 0.2843 - val_accuracy: 0.7667 - val_loss: 0.5068\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2392 - val_accuracy: 0.7667 - val_loss: 0.5096\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.2800 - val_accuracy: 0.7667 - val_loss: 0.5116\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.2707 - val_accuracy: 0.7667 - val_loss: 0.5143\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 0.3007 - val_accuracy: 0.7667 - val_loss: 0.5179\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.2732 - val_accuracy: 0.7667 - val_loss: 0.5194\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.2795 - val_accuracy: 0.7667 - val_loss: 0.5216\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8708 - loss: 0.2894 - val_accuracy: 0.7667 - val_loss: 0.5240\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: 0.2320 - val_accuracy: 0.7667 - val_loss: 0.5265\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8715 - loss: 0.2825 - val_accuracy: 0.7667 - val_loss: 0.5273\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.3083 - val_accuracy: 0.7667 - val_loss: 0.5299\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8732 - loss: 0.2723 - val_accuracy: 0.7667 - val_loss: 0.5316\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8807 - loss: 0.2651 - val_accuracy: 0.7667 - val_loss: 0.5341\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.2481 - val_accuracy: 0.7667 - val_loss: 0.5344\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.2622 - val_accuracy: 0.7667 - val_loss: 0.5373\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8911 - loss: 0.2319 - val_accuracy: 0.7667 - val_loss: 0.5397\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.2846 - val_accuracy: 0.7667 - val_loss: 0.5414\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9365 - loss: 0.1834 - val_accuracy: 0.7500 - val_loss: 0.5439\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.2808 - val_accuracy: 0.7500 - val_loss: 0.5466\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2258 - val_accuracy: 0.7500 - val_loss: 0.5503\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9335 - loss: 0.2000 - val_accuracy: 0.7500 - val_loss: 0.5491\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2511 - val_accuracy: 0.7500 - val_loss: 0.5522\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.2366 - val_accuracy: 0.7667 - val_loss: 0.5537\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2167 - val_accuracy: 0.7667 - val_loss: 0.5572\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9121 - loss: 0.2195 - val_accuracy: 0.7500 - val_loss: 0.5573\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9038 - loss: 0.2503 - val_accuracy: 0.7500 - val_loss: 0.5600\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.2248 - val_accuracy: 0.7500 - val_loss: 0.5634\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.2177 - val_accuracy: 0.7500 - val_loss: 0.5662\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.2962 - val_accuracy: 0.7500 - val_loss: 0.5685\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.2304 - val_accuracy: 0.7500 - val_loss: 0.5702\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.2274 - val_accuracy: 0.7500 - val_loss: 0.5744\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.2170 - val_accuracy: 0.7333 - val_loss: 0.5781\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8792 - loss: 0.2453 - val_accuracy: 0.7333 - val_loss: 0.5800\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2212 - val_accuracy: 0.7333 - val_loss: 0.5839\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8792 - loss: 0.2501 - val_accuracy: 0.7500 - val_loss: 0.5858\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.2213 - val_accuracy: 0.7500 - val_loss: 0.5869\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8856 - loss: 0.2691 - val_accuracy: 0.7500 - val_loss: 0.5908\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.2448 - val_accuracy: 0.7667 - val_loss: 0.5933\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.2209 - val_accuracy: 0.7667 - val_loss: 0.5966\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9372 - loss: 0.1930 - val_accuracy: 0.7500 - val_loss: 0.5995\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2090 - val_accuracy: 0.7500 - val_loss: 0.6013\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.2209 - val_accuracy: 0.7500 - val_loss: 0.6050\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 0.1991 - val_accuracy: 0.7500 - val_loss: 0.6085\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9029 - loss: 0.2382 - val_accuracy: 0.7667 - val_loss: 0.6102\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.2344 - val_accuracy: 0.7667 - val_loss: 0.6136\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9406 - loss: 0.2133 - val_accuracy: 0.7500 - val_loss: 0.6172\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9064 - loss: 0.2553 - val_accuracy: 0.7667 - val_loss: 0.6189\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9253 - loss: 0.2076 - val_accuracy: 0.7667 - val_loss: 0.6206\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1982 - val_accuracy: 0.7667 - val_loss: 0.6268\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 0.1893 - val_accuracy: 0.7667 - val_loss: 0.6249\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 0.2143 - val_accuracy: 0.7667 - val_loss: 0.6309\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1809 - val_accuracy: 0.7667 - val_loss: 0.6316\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1981 - val_accuracy: 0.7667 - val_loss: 0.6312\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9464 - loss: 0.1873 - val_accuracy: 0.7667 - val_loss: 0.6350\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9414 - loss: 0.2080 - val_accuracy: 0.7667 - val_loss: 0.6373\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9321 - loss: 0.1867 - val_accuracy: 0.7667 - val_loss: 0.6396\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.1653 - val_accuracy: 0.7667 - val_loss: 0.6405\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.2102 - val_accuracy: 0.7667 - val_loss: 0.6451\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.2065 - val_accuracy: 0.7667 - val_loss: 0.6464\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.2073 - val_accuracy: 0.7667 - val_loss: 0.6477\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9322 - loss: 0.2029 - val_accuracy: 0.7667 - val_loss: 0.6521\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.1886 - val_accuracy: 0.7667 - val_loss: 0.6551\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1711 - val_accuracy: 0.7667 - val_loss: 0.6583\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.2494 - val_accuracy: 0.7667 - val_loss: 0.6577\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9344 - loss: 0.2034 - val_accuracy: 0.7667 - val_loss: 0.6633\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2293 - val_accuracy: 0.7667 - val_loss: 0.6641\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1793 - val_accuracy: 0.7667 - val_loss: 0.6664\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.1585 - val_accuracy: 0.7667 - val_loss: 0.6691\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9312 - loss: 0.1936 - val_accuracy: 0.7667 - val_loss: 0.6720\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9529 - loss: 0.1695 - val_accuracy: 0.7667 - val_loss: 0.6745\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.1888 - val_accuracy: 0.7667 - val_loss: 0.6781\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1789 - val_accuracy: 0.7667 - val_loss: 0.6772\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9349 - loss: 0.1843 - val_accuracy: 0.7667 - val_loss: 0.6808\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9351 - loss: 0.2037 - val_accuracy: 0.7667 - val_loss: 0.6845\n",
            "Fine-Tuned Model 4 (More Epochs) Accuracy: 76.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results and Discussion:**\n",
        "\n",
        "Baseline Model:\n",
        "The baseline model achieved an accuracy of 76.67% on the test dataset. This model had a single hidden layer with 12 neurons and used the Adam optimizer with 50 epochs. The baseline performance indicates that the model is capable of learning the data patterns reasonably well.\n",
        "\n",
        "Fine-Tuned Model 1 (More Layers):\n",
        "Adding an additional hidden layer with 8 neurons reduced the accuracy to 70.00%. This decrease might be due to overfitting or the network becoming too complex for the given dataset.\n",
        "\n",
        "Fine-Tuned Model 2 (More Neurons):\n",
        "Increasing the number of neurons in the hidden layers also resulted in an accuracy of 70.00%. This indicates that merely adding more neurons without optimizing other hyperparameters does not necessarily improve performance.\n",
        "\n",
        "Fine-Tuned Model 3 (Different Optimizer):\n",
        "Replacing the Adam optimizer with SGD resulted in an accuracy of 71.67%. While SGD is a simpler optimizer, its performance lagged slightly behind Adam's. This highlights the importance of optimizer selection in neural network training.\n",
        "\n",
        "Fine-Tuned Model 4 (More Epochs):\n",
        "Increasing the number of epochs to 100 maintained the accuracy at 76.67%, which is equal to the baseline. This suggests that the model had already reached its optimal training level with 50 epochs.\n",
        "\n"
      ],
      "metadata": {
        "id": "hZlaLVx0Ua-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparative Study:**"
      ],
      "metadata": {
        "id": "9SWd6W2QYN43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "uqRP_CVYUlZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**:  \n",
        "\n",
        "The baseline model provided the best balance of simplicity and performance, achieving 76.67% accuracy.\n",
        "Adding additional layers or neurons did not improve performance and sometimes led to overfitting.\n",
        "Changing the optimizer from Adam to SGD resulted in slightly reduced performance, confirming that Adam is better suited for this dataset.\n",
        "Increasing the number of epochs beyond 50 had no significant effect, suggesting the model converges quickly."
      ],
      "metadata": {
        "id": "zfr6hizdXryO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References**:\n",
        "\n",
        "1] https://www.kaggle.com/datasets/cherngs/heart-disease-cleveland-uci\n",
        "\n",
        "2] https://medium.com/@stanleydukor/neural-representation-of-and-or-not-xor-and-xnor-logic-gates-perceptron-algorithm-b0275375fea1\n",
        "\n",
        "3] https://medium.com/analytics-vidhya/xor-gate-with-multilayer-perceptron-66e78671acd4\n",
        "\n",
        "4] https://www.datacamp.com/tutorial/multilayer-perceptrons-in-machine-learning\n"
      ],
      "metadata": {
        "id": "RU4OA_-IX_ah"
      }
    }
  ]
}