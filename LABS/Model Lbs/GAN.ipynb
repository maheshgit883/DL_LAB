{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================== OBJECTIVE =====================\n",
    "Objective:\n",
    "To design and implement a Generative Adversarial Network (GAN) that can generate realistic images\n",
    "resembling the given dataset images. The goal is to understand the data distribution and evaluate\n",
    "how well the model can synthesize new images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== MOUNT DRIVE (IF NEEDED) =====================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== IMPORT LIBRARIES =====================\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Dropout, Input, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== USER CONFIGURATION =====================\n",
    "use_mnist = True  # Set to False if using custom images\n",
    "image_folder = '/content/drive/MyDrive/your_image_folder'  # Only used if use_mnist is False\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 100\n",
    "save_interval = 5  # Save and display every 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== LOAD DATA =====================\n",
    "def load_images_from_folder(folder, img_shape):\n",
    "    images = []\n",
    "    for img_path in glob(os.path.join(folder, '*')):\n",
    "        try:\n",
    "            img = load_img(img_path, target_size=(img_shape[0], img_shape[1]), color_mode='grayscale' if img_shape[2] == 1 else 'rgb')\n",
    "            img = img_to_array(img) / 127.5 - 1.0  # Normalize to [-1, 1]\n",
    "            images.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "    return np.array(images)\n",
    "\n",
    "if use_mnist:\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "    X_train = X_train / 127.5 - 1.\n",
    "    X_train = np.expand_dims(X_train, axis=-1)\n",
    "else:\n",
    "    X_train = load_images_from_folder(image_folder, img_shape)\n",
    "\n",
    "print(\"Dataset loaded. Shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== BUILD GENERATOR =====================\n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "    model.add(Reshape(img_shape))\n",
    "\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== BUILD DISCRIMINATOR =====================\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== BUILD & COMPILE GAN =====================\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "generator = build_generator()\n",
    "z = Input(shape=(latent_dim,))\n",
    "img = generator(z)\n",
    "discriminator.trainable = False\n",
    "valid = discriminator(img)\n",
    "\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== SAVE GENERATED IMAGES =====================\n",
    "def save_images(epoch, generator, examples=16):\n",
    "    noise = np.random.normal(0, 1, (examples, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale to [0,1]\n",
    "\n",
    "    fig, axs = plt.subplots(4, 4, figsize=(5, 5))\n",
    "    cnt = 0\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axs[i, j].imshow(gen_imgs[cnt].squeeze(), cmap='gray' if channels == 1 else None)\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.suptitle(f\"Generated Images @ Epoch {epoch}\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== TRAIN THE GAN =====================\n",
    "epochs = 10000\n",
    "batch_size = 64\n",
    "\n",
    "valid = np.ones((batch_size, 1))\n",
    "fake = np.zeros((batch_size, 1))\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # Train Discriminator\n",
    "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    real_imgs = X_train[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch(real_imgs, valid)\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Train Generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    g_loss = combined.train_on_batch(noise, valid)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"[Epoch {epoch}] [D loss: {d_loss[0]:.4f}, acc.: {100*d_loss[1]:.2f}%] [G loss: {g_loss:.4f}]\")\n",
    "\n",
    "    # Save and display every 5 epochs\n",
    "    if epoch % save_interval == 0:\n",
    "        save_images(epoch, generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
