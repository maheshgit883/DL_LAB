{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb336ca",
   "metadata": {},
   "source": [
    "# Perceptron vs MLP: Universal Dataset Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e9a8d",
   "metadata": {},
   "source": [
    "## Aim / Objective\n",
    "To implement and compare the performance of the Perceptron algorithm and a Multilayer Perceptron (MLP) on a given dataset (image or CSV), and draw relevant inferences from performance metrics and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e10285",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "This notebook supports two types of datasets:\n",
    "- **CSV Dataset**: A numerical dataset (e.g., `Assess-1-QualityPrediction-numericalDataset.csv`) with features and labels.\n",
    "- **Image Dataset**: Images organized in folders by class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b8819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2112cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'csv'  # or 'image'\n",
    "# âœ… STEP 1: Mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1582b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == 'csv':\n",
    "    df = pd.read_csv('/content/drive/MyDrive/Assess-1-QualityPrediction-numericalDataset.csv')  # Adjust path as needed\n",
    "    print(\"Dataset Shape:\", df.shape)\n",
    "    df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15e83e",
   "metadata": {},
   "source": [
    "## Necessary Pre-processing / Visualization and its Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c22755",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == 'csv':\n",
    "    sns.heatmap(df.corr(), annot=True, fmt='.2f')\n",
    "    plt.title(\"Correlation Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Encode labels\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = LabelEncoder().fit_transform(df.iloc[:, -1])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59767543",
   "metadata": {},
   "source": [
    "## Design of the Model and its Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856541b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == 'csv':\n",
    "    print(\"### Perceptron Model ###\")\n",
    "    clf = Perceptron()\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Training Accuracy:\", clf.score(X_train, y_train))\n",
    "    print(\"Test Accuracy:\", clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b88879",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == 'csv':\n",
    "    class SimpleMLP(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            super(SimpleMLP, self).__init__()\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(input_dim, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, output_dim)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = len(set(y))\n",
    "    model = SimpleMLP(input_dim, output_dim).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "    train_losses, test_accuracies = [], []\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_test_tensor).argmax(dim=1)\n",
    "            acc = (preds == y_test_tensor).float().mean().item()\n",
    "            test_accuracies.append(acc)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Test Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce6a299",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.title(\"Epochs vs Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(test_accuracies)\n",
    "plt.title(\"Epochs vs Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b36477",
   "metadata": {},
   "source": [
    "## Performance Analysis (Class-wise Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83f1d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == 'csv':\n",
    "    print(\"Classification Report for Perceptron\")\n",
    "    print(classification_report(y_test, clf.predict(X_test)))\n",
    "\n",
    "    print(\"Classification Report for MLP\")\n",
    "    print(classification_report(y_test, preds.cpu().numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a4754",
   "metadata": {},
   "source": [
    "## Tabulated Results and Summary of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41769aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == 'csv':\n",
    "    results = {\n",
    "        'Model': ['Perceptron', 'MLP'],\n",
    "        'Accuracy': [clf.score(X_test, y_test), test_accuracies[-1]]\n",
    "    }\n",
    "    pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99f922",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The Multilayer Perceptron (MLP) model outperforms the traditional Perceptron in this dataset due to its ability to learn non-linear decision boundaries. While Perceptron is simpler and faster, MLP provides better generalization."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
