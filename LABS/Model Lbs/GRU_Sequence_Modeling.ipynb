{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea37c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================== OBJECTIVE ================== \n",
    "\"\"\"\n",
    "Aim: To implement a sequence model using a custom GRU architecture\n",
    "for both classification and regression tasks.\n",
    "\"\"\"\n",
    "\n",
    "# ================== MOUNT GOOGLE DRIVE ==================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ================== IMPORTS ==================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "\n",
    "# ================== USER CONFIGURATION ==================\n",
    "task_type = \"classification\"  # Choose: \"classification\" or \"regression\"\n",
    "data_path = '/content/drive/MyDrive/your_dataset.csv'  # Replace with your dataset path\n",
    "target_col = 'target'  # Replace with the name of your target column\n",
    "SEQ_LEN = 10  # Length of sequences for GRU\n",
    "\n",
    "# ================== LOAD DATA ==================\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"First few rows:\\n\", df.head())\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# ================== HANDLE MISSING VALUES (IF ANY) ==================\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ================== ENCODING & SCALING ==================\n",
    "if task_type == 'classification' and df[target_col].dtype == object:\n",
    "    le = LabelEncoder()\n",
    "    df[target_col] = le.fit_transform(df[target_col])\n",
    "\n",
    "features = df.drop(columns=[target_col])\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "target = df[target_col].values\n",
    "\n",
    "# ================== CREATE SEQUENCES ==================\n",
    "def create_sequences(X, y, seq_len=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_len):\n",
    "        Xs.append(X[i:i+seq_len])\n",
    "        ys.append(y[i+seq_len])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X, y = create_sequences(scaled_features, target, SEQ_LEN)\n",
    "\n",
    "# ================== SPLIT DATA ==================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ================== VISUALIZATION ==================\n",
    "if task_type == 'classification':\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.countplot(x=y)\n",
    "    plt.title(\"Target Class Distribution\")\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.hist(y, bins=30)\n",
    "    plt.title(\"Target Value Distribution\")\n",
    "    plt.xlabel(\"Target\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "# ================== BASELINE MODEL ==================\n",
    "baseline_model = Sequential()\n",
    "baseline_model.add(GRU(32, input_shape=(X.shape[1], X.shape[2])))\n",
    "baseline_model.add(Dense(1 if task_type == \"regression\" else len(np.unique(y)), \n",
    "                         activation=None if task_type == \"regression\" else \"softmax\"))\n",
    "\n",
    "baseline_model.compile(\n",
    "    loss='mse' if task_type == 'regression' else 'sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['mae'] if task_type == 'regression' else ['accuracy']\n",
    ")\n",
    "\n",
    "baseline_model.fit(X_train, y_train, epochs=5, validation_split=0.2, verbose=0)\n",
    "\n",
    "# ================== CUSTOM GRU MODEL ==================\n",
    "model = Sequential()\n",
    "model.add(GRU(128, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(GRU(64))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "if task_type == 'regression':\n",
    "    model.add(Dense(1))\n",
    "    loss_fn = 'mse'\n",
    "    metrics = ['mae']\n",
    "else:\n",
    "    model.add(Dense(len(np.unique(y)), activation='softmax'))\n",
    "    loss_fn = 'sparse_categorical_crossentropy'\n",
    "    metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer='adam', metrics=metrics)\n",
    "model.summary()\n",
    "\n",
    "# ================== TRAINING ==================\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_split=0.2,\n",
    "                    batch_size=32, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ================== TRAINING PLOTS ==================\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[metrics[0]], label='Train')\n",
    "plt.plot(history.history['val_' + metrics[0]], label='Validation')\n",
    "plt.title(f'Epochs vs {metrics[0].capitalize()}')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(metrics[0].capitalize())\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Epochs vs Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ================== PERFORMANCE EVALUATION ==================\n",
    "if task_type == \"classification\":\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"\\nMean Squared Error: {mse:.4f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.title(\"True vs Predicted\")\n",
    "    plt.xlabel(\"True Values\")\n",
    "    plt.ylabel(\"Predicted Values\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# ================== RESULT TABLE ==================\n",
    "baseline_metric = baseline_model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "custom_metric = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'Model': ['Baseline GRU', 'Custom GRU'],\n",
    "    f'{metrics[0].capitalize()}': [baseline_metric, custom_metric]\n",
    "})\n",
    "print(\"\\nModel Comparison:\\n\", result_df)\n",
    "\n",
    "# ================== CONCLUSION ==================\n",
    "\"\"\"\n",
    "Conclusion:\n",
    "- The GRU-based framework handles both classification and regression tasks.\n",
    "- Custom model improves over baseline using additional GRU layers, dropout, and tuning.\n",
    "- For classification: evaluated using accuracy & classification report.\n",
    "- For regression: evaluated using MAE, MSE, and RÂ² Score.\n",
    "- The same code can be reused for any time-sequential dataset by simply switching the task_type.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
